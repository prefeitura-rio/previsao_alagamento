{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import basedosdados as bd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score, brier_score_loss, precision_recall_curve, auc\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.svm import SVC, OneClassSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO rode isto para criar o csv com vários hexágonos (O finalizado)\n",
    "# main_table = bd.read_sql(query = \"\"\" SELECT * FROM `rj-cor-dev.clima_pluviometro.main_table_fields_1H_mais_frequentes`\"\"\", billing_project_id = \"projeto-fgv1\", use_bqstorage_api = True)\n",
    "# main_table.to_csv(\"csvs/main_table_mult_hexag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_table_k = pd.read_csv(\"csvs/main_table_mult_hexag.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_table = main_table_k.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_table.fillna(0, inplace=True)\n",
    "\n",
    "main_table[\"target\"] = main_table[\"alagamento_pop\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "main_table[\"id_h3\"] = main_table[\"id_h3\"].astype(\"category\")\n",
    "\n",
    "# Aplicar one-hot encoding na coluna \"estacao_ano\"\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded_cols = one_hot_encoder.fit_transform(main_table[[\"estacao_ano\"]])\n",
    "encoded_labels = one_hot_encoder.categories_[0]\n",
    "\n",
    "# Adicionar as colunas codificadas ao DataFrame original\n",
    "for i, label in enumerate(encoded_labels):\n",
    "    main_table[f\"estacao_ano_{label}\"] = encoded_cols[:, i]\n",
    "\n",
    "\n",
    "# Transformar a coluna id_h3 em categórica\n",
    "label_encoder = LabelEncoder()\n",
    "main_table[\"id_h3\"] = label_encoder.fit_transform(main_table[\"id_h3\"])\n",
    "\n",
    "\n",
    "main_table.drop(columns=[\"data_hora\", \"estacao_ano\", \"alagamento_fim\",\n",
    "                         \"estacoes\", \"Unnamed: 0\", \"alagamento_pop\", \"alagamento_inicio\", \n",
    "                         \"quinzenas\", \"alagamento_lat\", \"alagamento_long\", \"id_alagamento\",\n",
    "                         \"gravidade_alagamento\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_h3</th>\n",
       "      <th>chuva_15min</th>\n",
       "      <th>chuva_1h</th>\n",
       "      <th>chuva_4h</th>\n",
       "      <th>chuva_24h</th>\n",
       "      <th>chuva_96h</th>\n",
       "      <th>estacao_ano_Inverno</th>\n",
       "      <th>estacao_ano_Outono</th>\n",
       "      <th>estacao_ano_Primavera</th>\n",
       "      <th>estacao_ano_Verão</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1169904</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669389</th>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774759</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>18.331036</td>\n",
       "      <td>11.921848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4033651</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258501</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698271</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719309</th>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.417596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514465</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.804468</td>\n",
       "      <td>13.225380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749992</th>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.042105</td>\n",
       "      <td>39.104516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069279</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605277 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_h3  chuva_15min  chuva_1h  chuva_4h  chuva_24h  chuva_96h  \\\n",
       "1169904     46          0.0       0.0  0.000000   0.000000   0.200000   \n",
       "669389      29          0.0       0.0  0.000000   0.000000   0.000000   \n",
       "2774759     22          0.0       0.0  0.068917  18.331036  11.921848   \n",
       "4033651      1          0.0       0.0  0.000000   0.000000   0.000000   \n",
       "2258501     25          0.0       0.0  0.000000   0.000000   0.000000   \n",
       "...        ...          ...       ...       ...        ...        ...   \n",
       "3698271     11          0.0       0.0  0.000000   0.000000   0.799812   \n",
       "1719309     47          0.0       0.0  0.000000   0.000000  11.417596   \n",
       "1514465      9          0.0       0.0  0.000000   8.804468  13.225380   \n",
       "3749992     26          0.0       0.0  0.000000   3.042105  39.104516   \n",
       "1069279      9          0.0       0.0  0.000000   0.000000   0.000000   \n",
       "\n",
       "         estacao_ano_Inverno  estacao_ano_Outono  estacao_ano_Primavera  \\\n",
       "1169904                  0.0                 0.0                    0.0   \n",
       "669389                   1.0                 0.0                    0.0   \n",
       "2774759                  0.0                 0.0                    0.0   \n",
       "4033651                  0.0                 0.0                    1.0   \n",
       "2258501                  1.0                 0.0                    0.0   \n",
       "...                      ...                 ...                    ...   \n",
       "3698271                  1.0                 0.0                    0.0   \n",
       "1719309                  0.0                 1.0                    0.0   \n",
       "1514465                  0.0                 0.0                    0.0   \n",
       "3749992                  0.0                 0.0                    1.0   \n",
       "1069279                  0.0                 0.0                    1.0   \n",
       "\n",
       "         estacao_ano_Verão  \n",
       "1169904                1.0  \n",
       "669389                 0.0  \n",
       "2774759                1.0  \n",
       "4033651                0.0  \n",
       "2258501                0.0  \n",
       "...                    ...  \n",
       "3698271                0.0  \n",
       "1719309                0.0  \n",
       "1514465                1.0  \n",
       "3749992                0.0  \n",
       "1069279                0.0  \n",
       "\n",
       "[605277 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = main_table.drop(columns=[\"target\"])\n",
    "y = main_table[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "std = StandardScaler()\n",
    "\n",
    "X_train_standard = std.fit_transform(X_train)\n",
    "X_val_standard = std.transform(X_val)\n",
    "X_test_standard = std.transform(X_test)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Model\n",
      "R2:  -0.0020379242640451434\n",
      "MSE:  0.0020337795753018867\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "F0.5:  0.0\n",
      "Area under Precision Recall Curve:  0.49898311021234903\n",
      "Brier Score:  0.0020337795753018867\n",
      "Confusion Matrix: \n",
      " [[604046      0]\n",
      " [  1231      0]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Model\n",
    "# predicts majority class always\n",
    "\n",
    "# predictid minority proportion\n",
    "\n",
    "naive_pred = np.ones(len(y_test)) * y_train.mean()\n",
    "y_pred_nv = np.where(naive_pred > 0.5, 1, 0)\n",
    "\n",
    "# metrics\n",
    "print(\"Naive Model\")\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred_nv))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred_nv))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred_nv))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_nv))\n",
    "print(\"F0.5: \", fbeta_score(y_test, y_pred_nv, beta=0.5))\n",
    "recall_nv, precision_nv, th_nv = precision_recall_curve(y_test, y_pred_nv)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_nv, precision_nv))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_nv))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred_nv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -0.037854064530184806\n",
      "Precison:  0.36585365853658536\n",
      "Recall:  0.048740861088545896\n",
      "Brier Score:  0.0021064735649958615\n",
      "F-0.5 Score:  0.1589825119236884\n",
      "Area under Precision Recall Curve:  0.20623080594103244\n",
      "confusion_matrix: \n",
      " [[603942    104]\n",
      " [  1171     60]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_standard, y_train)\n",
    "\n",
    "y_pred_lr = logreg.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_lr))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_lr))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_lr))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_lr))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_lr, beta=0.5))\n",
    "recall_lr, precision_lr, th_lr = precision_recall_curve(y_test, y_pred_lr)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_lr, precision_lr))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  0.05168628613516435\n",
      "Precison:  0.8202265412860429\n",
      "Recall:  0.5604511991413827\n",
      "Brier Score:  0.0019247385907609244\n",
      "F-0.5 Score:  0.3450671607225568\n",
      "Area under Precision Recall Curve:  0.3805006182441584\n",
      "confusion_matrix: \n",
      " [[603963     83]\n",
      " [  1082    149]]\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train_standard, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_knn))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_knn, average=\"macro\"))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_knn, average=\"macro\"))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_knn))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_knn, beta=0.5))\n",
    "recall_knn, precision_knn, th_knn = precision_recall_curve(y_test, y_pred_knn)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_knn, precision_knn))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -0.0012239210761784136\n",
      "Precison:  0.5151515151515151\n",
      "Recall:  0.01380991064175467\n",
      "Brier Score:  0.0020321274391724782\n",
      "F-0.5 Score:  0.0623624358033749\n",
      "Area under Precision Recall Curve:  0.26344977995188396\n",
      "confusion_matrix: \n",
      " [[604030     16]\n",
      " [  1214     17]]\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "\n",
    "# 10 camadas ocultas com 10 neurônios cada relu\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=1000, activation=\"relu\", \n",
    "                    solver=\"adam\", random_state=1, early_stopping=True)\n",
    "mlp.fit(X_train_standard, y_train)\n",
    "\n",
    "y_pred_nn = mlp.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_nn))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_nn))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_nn))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_nn))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_nn, beta=0.5))\n",
    "recall_nn, precision_nn, th_nn = precision_recall_curve(y_test, y_pred_nn)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_nn, precision_nn))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -0.2226327881759511\n",
      "Precison:  0.3942232630757221\n",
      "Recall:  0.4102355808285946\n",
      "Brier Score:  0.0024815084663715953\n",
      "F-0.5 Score:  0.39732494099134535\n",
      "Area under Precision Recall Curve:  0.4007953677918318\n",
      "confusion matrix:\n",
      " [[603270    776]\n",
      " [   726    505]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_dt))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_dt))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_dt))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_dt))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_dt, beta=0.5))\n",
    "recall_dt, precision_dt, th_dt = precision_recall_curve(y_test, y_pred_dt)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_dt, precision_dt))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  0.1965788535754569\n",
      "Precison:  0.7904761904761904\n",
      "Recall:  0.2696994313566206\n",
      "Brier Score:  0.001630658359726208\n",
      "F-0.5 Score:  0.5702507729302644\n",
      "Area under Precision Recall Curve:  0.5287966665312727\n",
      "confusion matrix:\n",
      " [[603958     88]\n",
      " [   899    332]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10, criterion=\"entropy\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_rf))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_rf))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_rf))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_rf, beta=0.5))\n",
    "recall_rf, precision_rf, th_rf = precision_recall_curve(y_test, y_pred_rf)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_rf, precision_rf))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  0.2526258448747565\n",
      "Precison:  0.8958333333333334\n",
      "Recall:  0.296551724137931\n",
      "Brier Score:  0.009323806204252353\n",
      "F-0.5 Score:  0.6379821958456974\n",
      "Area under Precision Recall Curve:  0.5880015214160087\n",
      "confusion matrix:\n",
      " [[11326     5]\n",
      " [  102    43]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "svm.fit(X_train_standard, y_train)\n",
    "\n",
    "y_pred_svm = svm.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_svm))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_svm))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_svm))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_svm, beta=0.5))\n",
    "recall_svm, precision_svm, th_svm = precision_recall_curve(y_test, y_pred_svm)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_svm, precision_svm))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -0.2950790718960974\n",
      "Precison:  0.2009966777408638\n",
      "Recall:  0.0982940698619009\n",
      "Brier Score:  0.0026285485818889533\n",
      "F-0.5 Score:  0.16625446551250342\n",
      "Area under Precision Recall Curve:  0.1485285297779022\n",
      "confusion matrix:\n",
      " [[603565    481]\n",
      " [  1110    121]]\n"
     ]
    }
   ],
   "source": [
    "# Isolation Forest\n",
    "\n",
    "isolation_forest = IsolationForest(n_estimators=100, contamination=0.001)\n",
    "isolation_forest.fit(X_train)\n",
    "\n",
    "y_pred_if = isolation_forest.predict(X_test)\n",
    "y_pred_if = np.where(y_pred_if == -1, 1, 0)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_if))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_if))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_if))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_if))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_if, beta=0.5))\n",
    "recall_if, precision_if, th_if = precision_recall_curve(y_test, y_pred_if)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_if, precision_if))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_if))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -41.6422356732674\n",
      "Precison:  0.02059202059202059\n",
      "Recall:  0.8827586206896552\n",
      "Brier Score:  0.5319797838968282\n",
      "F-0.5 Score:  0.025590787316566034\n",
      "Area under Precision Recall Curve:  0.4397809323522356\n",
      "confusion matrix:\n",
      " [[5243 6088]\n",
      " [  17  128]]\n"
     ]
    }
   ],
   "source": [
    "# One Class SVM\n",
    "\n",
    "one_class_svm = OneClassSVM()\n",
    "one_class_svm.fit(X_train_standard)\n",
    "\n",
    "y_pred_ocs = one_class_svm.predict(X_test_standard)\n",
    "y_pred_ocs = np.where(y_pred_ocs == -1, 1, 0)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_ocs))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_ocs))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_ocs))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_ocs))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_ocs, beta=0.5))\n",
    "recall_ocs, precision_ocs, th_ocs = precision_recall_curve(y_test, y_pred_ocs)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_ocs, precision_ocs))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_ocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Outlier Factor\n",
    "\n",
    "local_outlier_factor = LocalOutlierFactor(n_neighbors=20, contamination=0.01, novelty=True)\n",
    "local_outlier_factor.fit(X_train_standard)\n",
    "\n",
    "y_pred_lof = local_outlier_factor.predict(X_test_standard)\n",
    "y_pred_lof = np.where(y_pred_lof == -1, 1, 0)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_lof))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_lof))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_lof))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_lof))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_lof, beta=0.5))\n",
    "recall_lof, precision_lof, th_lof = precision_recall_curve(y_test, y_pred_lof)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_lof, precision_lof))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_lof))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prefeitura_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
