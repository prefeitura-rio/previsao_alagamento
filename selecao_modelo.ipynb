{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import basedosdados as bd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score, brier_score_loss, precision_recall_curve, auc\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.svm import SVC, OneClassSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO rode isto para criar o csv com vários hexágonos (O finalizado)\n",
    "# main_table = bd.read_sql(query = \"\"\" SELECT * FROM `rj-cor-dev.clima_pluviometro.main_table_fields_1H_mais_frequentes`\"\"\", billing_project_id = \"projeto-fgv1\", use_bqstorage_api = True)\n",
    "# main_table.to_csv(\"csvs/main_table_mult_hexag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_table_k = pd.read_csv(\"csvs/main_table_mult_hexag.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_table = main_table_k.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_table.fillna(0, inplace=True)\n",
    "\n",
    "main_table[\"target\"] = main_table[\"alagamento_pop\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "main_table[\"id_h3\"] = main_table[\"id_h3\"].astype(\"category\")\n",
    "\n",
    "# Aplicar one-hot encoding na coluna \"estacao_ano\"\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded_cols = one_hot_encoder.fit_transform(main_table[[\"estacao_ano\"]])\n",
    "encoded_labels = one_hot_encoder.categories_[0]\n",
    "\n",
    "# Adicionar as colunas codificadas ao DataFrame original\n",
    "for i, label in enumerate(encoded_labels):\n",
    "    main_table[f\"estacao_ano_{label}\"] = encoded_cols[:, i]\n",
    "\n",
    "\n",
    "# Transformar a coluna id_h3 em categórica\n",
    "label_encoder = LabelEncoder()\n",
    "main_table[\"id_h3\"] = label_encoder.fit_transform(main_table[\"id_h3\"])\n",
    "\n",
    "\n",
    "main_table.drop(columns=[\"data_hora\", \"estacao_ano\", \"alagamento_fim\",\n",
    "                         \"estacoes\", \"Unnamed: 0\", \"alagamento_pop\", \"alagamento_inicio\", \n",
    "                         \"quinzenas\", \"alagamento_lat\", \"alagamento_long\", \"id_alagamento\",\n",
    "                         \"gravidade_alagamento\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_h3</th>\n",
       "      <th>chuva_15min</th>\n",
       "      <th>chuva_1h</th>\n",
       "      <th>chuva_4h</th>\n",
       "      <th>chuva_24h</th>\n",
       "      <th>chuva_96h</th>\n",
       "      <th>estacao_ano_Inverno</th>\n",
       "      <th>estacao_ano_Outono</th>\n",
       "      <th>estacao_ano_Primavera</th>\n",
       "      <th>estacao_ano_Verão</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1187439</th>\n",
       "      <td>49</td>\n",
       "      <td>0.599317</td>\n",
       "      <td>2.600339</td>\n",
       "      <td>1.741515e+01</td>\n",
       "      <td>24.436614</td>\n",
       "      <td>40.027015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985198</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.012229</td>\n",
       "      <td>0.692578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982444</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.202850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945507</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.789241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543190</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>28.797095</td>\n",
       "      <td>28.797095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517434</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.510000e-07</td>\n",
       "      <td>4.200053</td>\n",
       "      <td>4.200053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332888</th>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680138</th>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150023</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542149</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.399999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605277 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_h3  chuva_15min  chuva_1h      chuva_4h  chuva_24h  chuva_96h  \\\n",
       "1187439     49     0.599317  2.600339  1.741515e+01  24.436614  40.027015   \n",
       "985198      15     0.000000  0.000000  0.000000e+00   0.012229   0.692578   \n",
       "1982444     23     0.000000  0.000000  0.000000e+00   0.000000   2.202850   \n",
       "1945507     19     0.000000  0.000000  0.000000e+00   0.000000  12.789241   \n",
       "1543190     11     0.000000  0.000000  0.000000e+00  28.797095  28.797095   \n",
       "...        ...          ...       ...           ...        ...        ...   \n",
       "2517434      4     0.000000  0.000000  4.510000e-07   4.200053   4.200053   \n",
       "3332888     46     0.000000  0.000000  0.000000e+00   0.000000   0.000000   \n",
       "1680138     43     0.000000  0.000000  0.000000e+00   0.000000   0.000000   \n",
       "2150023     14     0.000000  0.000000  0.000000e+00   0.000000   0.380969   \n",
       "1542149      4     0.000000  0.000000  0.000000e+00   0.200000   0.399999   \n",
       "\n",
       "         estacao_ano_Inverno  estacao_ano_Outono  estacao_ano_Primavera  \\\n",
       "1187439                  0.0                 1.0                    0.0   \n",
       "985198                   0.0                 0.0                    1.0   \n",
       "1982444                  0.0                 0.0                    0.0   \n",
       "1945507                  0.0                 0.0                    1.0   \n",
       "1543190                  0.0                 0.0                    1.0   \n",
       "...                      ...                 ...                    ...   \n",
       "2517434                  0.0                 1.0                    0.0   \n",
       "3332888                  0.0                 0.0                    1.0   \n",
       "1680138                  0.0                 0.0                    1.0   \n",
       "2150023                  0.0                 1.0                    0.0   \n",
       "1542149                  0.0                 0.0                    1.0   \n",
       "\n",
       "         estacao_ano_Verão  \n",
       "1187439                0.0  \n",
       "985198                 0.0  \n",
       "1982444                1.0  \n",
       "1945507                0.0  \n",
       "1543190                0.0  \n",
       "...                    ...  \n",
       "2517434                0.0  \n",
       "3332888                0.0  \n",
       "1680138                0.0  \n",
       "2150023                0.0  \n",
       "1542149                0.0  \n",
       "\n",
       "[605277 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = main_table.drop(columns=[\"target\"])\n",
    "y = main_table[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "std = StandardScaler()\n",
    "\n",
    "X_train_standard = std.fit_transform(X_train)\n",
    "X_val_standard = std.transform(X_val)\n",
    "X_test_standard = std.transform(X_test)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Model\n",
      "R2:  -0.0019201578502179295\n",
      "MSE:  0.0019164779101138818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "F0.5:  0.0\n",
      "Area under Precision Recall Curve:  0.4990417610449431\n",
      "Brier Score:  0.0019164779101138818\n",
      "Confusion Matrix: \n",
      " [[604117      0]\n",
      " [  1160      0]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Model\n",
    "# predicts majority class always\n",
    "\n",
    "# predictid minority proportion\n",
    "\n",
    "naive_pred = np.ones(len(y_test)) * y_train.mean()\n",
    "y_pred_nv = np.where(naive_pred > 0.5, 1, 0)\n",
    "\n",
    "# metrics\n",
    "print(\"Naive Model\")\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred_nv))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred_nv))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred_nv))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_nv))\n",
    "print(\"F0.5: \", fbeta_score(y_test, y_pred_nv, beta=0.5))\n",
    "recall_nv, precision_nv, th_nv = precision_recall_curve(y_test, y_pred_nv)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_nv, precision_nv))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_nv))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred_nv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -0.031188295272667643\n",
      "Precison:  0.40425531914893614\n",
      "Recall:  0.061389337641357025\n",
      "Brier Score:  0.002104821428866453\n",
      "F-0.5 Score:  0.1909547738693467\n",
      "Area under Precision Recall Curve:  0.23173687495812517\n",
      "confusion_matrix: \n",
      " [[603927    112]\n",
      " [  1162     76]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_standard, y_train)\n",
    "\n",
    "y_pred_lr = logreg.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_lr))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_lr))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_lr))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_lr))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_lr, beta=0.5))\n",
    "recall_lr, precision_lr, th_lr = precision_recall_curve(y_test, y_pred_lr)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_lr, precision_lr))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -11.225153374320678\n",
      "Precison:  0.04502801120448179\n",
      "Recall:  0.5543103448275862\n",
      "Brier Score:  0.023384334775648174\n",
      "F-0.5 Score:  0.05516472203157173\n",
      "Area under Precision Recall Curve:  0.29817977729537226\n",
      "confusion_matrix: \n",
      " [[590480  13637]\n",
      " [   517    643]]\n"
     ]
    }
   ],
   "source": [
    "# naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_standard, y_train)\n",
    "\n",
    "y_pred_gnb = gnb.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_gnb))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_gnb))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_gnb))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_gnb))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_gnb, beta=0.5))\n",
    "recall_gnb, precision_gnb, th_gnb = precision_recall_curve(y_test, y_pred_gnb)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_gnb, precision_gnb))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, y_pred_gnb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  0.0465150613569838\n",
      "Precison:  0.8148854146741138\n",
      "Recall:  0.558088787936563\n",
      "Brier Score:  0.0019462163604432351\n",
      "F-0.5 Score:  0.3348837209302326\n",
      "Area under Precision Recall Curve:  0.3728061674895485\n",
      "confusion_matrix: \n",
      " [[603955     84]\n",
      " [  1094    144]]\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train_standard, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_knn))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_knn, average=\"macro\"))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_knn, average=\"macro\"))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_knn))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_knn, beta=0.5))\n",
    "recall_knn, precision_knn, th_knn = precision_recall_curve(y_test, y_pred_knn)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_knn, precision_knn))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\otavi\\Desktop\\prefeitura\\previsao_alagamento\\selecao_modelo.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/otavi/Desktop/prefeitura/previsao_alagamento/selecao_modelo.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Neural Network\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/otavi/Desktop/prefeitura/previsao_alagamento/selecao_modelo.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m a\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/otavi/Desktop/prefeitura/previsao_alagamento/selecao_modelo.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# 10 camadas ocultas com 10 neurônios cada relu\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/otavi/Desktop/prefeitura/previsao_alagamento/selecao_modelo.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mlp \u001b[39m=\u001b[39m MLPClassifier(hidden_layer_sizes\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m), max_iter\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/otavi/Desktop/prefeitura/previsao_alagamento/selecao_modelo.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     solver\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, early_stopping\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "a\n",
    "# 10 camadas ocultas com 10 neurônios cada relu\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=1000, activation=\"relu\", \n",
    "                    solver=\"adam\", random_state=1, early_stopping=True)\n",
    "mlp.fit(X_train_standard, y_train)\n",
    "\n",
    "y_pred_nn = mlp.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_nn))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_nn))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_nn))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_nn))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_nn, beta=0.5))\n",
    "recall_nn, precision_nn, th_nn = precision_recall_curve(y_test, y_pred_nn)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_nn, precision_nn))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -0.2226327881759511\n",
      "Precison:  0.3942232630757221\n",
      "Recall:  0.4102355808285946\n",
      "Brier Score:  0.0024815084663715953\n",
      "F-0.5 Score:  0.39732494099134535\n",
      "Area under Precision Recall Curve:  0.4007953677918318\n",
      "confusion matrix:\n",
      " [[603270    776]\n",
      " [   726    505]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_dt))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_dt))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_dt))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_dt))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_dt, beta=0.5))\n",
    "recall_dt, precision_dt, th_dt = precision_recall_curve(y_test, y_pred_dt)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_dt, precision_dt))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  0.1965788535754569\n",
      "Precison:  0.7904761904761904\n",
      "Recall:  0.2696994313566206\n",
      "Brier Score:  0.001630658359726208\n",
      "F-0.5 Score:  0.5702507729302644\n",
      "Area under Precision Recall Curve:  0.5287966665312727\n",
      "confusion matrix:\n",
      " [[603958     88]\n",
      " [   899    332]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10, criterion=\"entropy\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_rf))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_rf))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_rf))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_rf, beta=0.5))\n",
    "recall_rf, precision_rf, th_rf = precision_recall_curve(y_test, y_pred_rf)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_rf, precision_rf))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "svm = SVC(kernel=\"rbf\", gamma=\"auto\", verbose=2)\n",
    "\n",
    "svm.fit(X_train_standard, y_train)\n",
    "\n",
    "y_pred_svm = svm.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_svm))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_svm))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_svm))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_svm, beta=0.5))\n",
    "recall_svm, precision_svm, th_svm = precision_recall_curve(y_test, y_pred_svm)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_svm, precision_svm))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -0.2950790718960974\n",
      "Precison:  0.2009966777408638\n",
      "Recall:  0.0982940698619009\n",
      "Brier Score:  0.0026285485818889533\n",
      "F-0.5 Score:  0.16625446551250342\n",
      "Area under Precision Recall Curve:  0.1485285297779022\n",
      "confusion matrix:\n",
      " [[603565    481]\n",
      " [  1110    121]]\n"
     ]
    }
   ],
   "source": [
    "# Isolation Forest\n",
    "\n",
    "isolation_forest = IsolationForest(n_estimators=100, contamination=0.001)\n",
    "isolation_forest.fit(X_train)\n",
    "\n",
    "y_pred_if = isolation_forest.predict(X_test)\n",
    "y_pred_if = np.where(y_pred_if == -1, 1, 0)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_if))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_if))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_if))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_if))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_if, beta=0.5))\n",
    "recall_if, precision_if, th_if = precision_recall_curve(y_test, y_pred_if)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_if, precision_if))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_if))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -41.6422356732674\n",
      "Precison:  0.02059202059202059\n",
      "Recall:  0.8827586206896552\n",
      "Brier Score:  0.5319797838968282\n",
      "F-0.5 Score:  0.025590787316566034\n",
      "Area under Precision Recall Curve:  0.4397809323522356\n",
      "confusion matrix:\n",
      " [[5243 6088]\n",
      " [  17  128]]\n"
     ]
    }
   ],
   "source": [
    "# One Class SVM\n",
    "\n",
    "one_class_svm = OneClassSVM()\n",
    "one_class_svm.fit(X_train_standard)\n",
    "\n",
    "y_pred_ocs = one_class_svm.predict(X_test_standard)\n",
    "y_pred_ocs = np.where(y_pred_ocs == -1, 1, 0)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_ocs))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_ocs))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_ocs))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_ocs))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_ocs, beta=0.5))\n",
    "recall_ocs, precision_ocs, th_ocs = precision_recall_curve(y_test, y_pred_ocs)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_ocs, precision_ocs))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_ocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Outlier Factor\n",
    "\n",
    "local_outlier_factor = LocalOutlierFactor(n_neighbors=20, contamination=0.01, novelty=True)\n",
    "local_outlier_factor.fit(X_train_standard)\n",
    "\n",
    "y_pred_lof = local_outlier_factor.predict(X_test_standard)\n",
    "y_pred_lof = np.where(y_pred_lof == -1, 1, 0)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_lof))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_lof))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_lof))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_lof))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_lof, beta=0.5))\n",
    "recall_lof, precision_lof, th_lof = precision_recall_curve(y_test, y_pred_lof)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_lof, precision_lof))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_lof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -40.05273281433582\n",
      "Precison:  0.018803139306736428\n",
      "Recall:  0.7809847198641766\n",
      "Brier Score:  0.07974200242203157\n",
      "F-0.5 Score:  0.023363299304179998\n",
      "Area under Precision Recall Curve:  0.398160838785707\n",
      "confusion_matrix: \n",
      " [[556091  48008]\n",
      " [   258    920]]\n"
     ]
    }
   ],
   "source": [
    "# Smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_standard, y_train)\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_lr = logreg.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_lr))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_lr))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_lr))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_lr))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_lr, beta=0.5))\n",
    "recall_lr, precision_lr, th_lr = precision_recall_curve(y_test, y_pred_lr)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_lr, precision_lr))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -60.03899883329871\n",
      "Precison:  0.013883915043662709\n",
      "Recall:  0.8556876061120543\n",
      "Brier Score:  0.11856389719087294\n",
      "F-0.5 Score:  0.01728478047642891\n",
      "Area under Precision Recall Curve:  0.432979975788415\n",
      "confusion_matrix: \n",
      " [[532505  71594]\n",
      " [   170   1008]]\n"
     ]
    }
   ],
   "source": [
    "# neural network\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=1000, activation=\"relu\",\n",
    "                    solver=\"adam\", random_state=1, early_stopping=True)\n",
    "mlp.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_nn = mlp.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_nn))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_nn))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_nn))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_nn))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_nn, beta=0.5))\n",
    "recall_nn, precision_nn, th_nn = precision_recall_curve(y_test, y_pred_nn)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_nn, precision_nn))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -5.953260903269285\n",
      "Precison:  0.024983027834351662\n",
      "Recall:  0.15619694397283532\n",
      "Brier Score:  0.01350621285791464\n",
      "F-0.5 Score:  0.030028069717344473\n",
      "Area under Precision Recall Curve:  0.08946488119946629\n",
      "confusion matrix:\n",
      " [[596918   7181]\n",
      " [   994    184]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_dt))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_dt))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_dt))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_dt))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_dt, beta=0.5))\n",
    "recall_dt, precision_dt, th_dt = precision_recall_curve(y_test, y_pred_dt)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_dt, precision_dt))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -2.9856856994152747\n",
      "Precison:  0.025175961017866812\n",
      "Recall:  0.07894736842105263\n",
      "Brier Score:  0.007741909902408319\n",
      "F-0.5 Score:  0.02914629559984957\n",
      "Area under Precision Recall Curve:  0.05101173220922061\n",
      "confusion matrix:\n",
      " [[600498   3601]\n",
      " [  1085     93]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10, criterion=\"entropy\")\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_rf))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_rf))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_rf))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_rf, beta=0.5))\n",
    "recall_rf, precision_rf, th_rf = precision_recall_curve(y_test, y_pred_rf)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_rf, precision_rf))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -7.547194962318416\n",
      "Precison:  0.5376349519349483\n",
      "Recall:  0.8290123679145666\n",
      "Brier Score:  0.016602315964426205\n",
      "F-0.5 Score:  0.09229553168735759\n",
      "Area under Precision Recall Curve:  0.37334061807216173\n",
      "confusion_matrix: \n",
      " [[594434   9665]\n",
      " [   384    794]]\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "knn.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_knn))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_knn, average=\"macro\"))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_knn, average=\"macro\"))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_knn))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_knn, beta=0.5))\n",
    "recall_knn, precision_knn, th_knn = precision_recall_curve(y_test, y_pred_knn)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_knn, precision_knn))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "\n",
    "svm = SVC(verbose=True)\n",
    "\n",
    "svm.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_svm = svm.predict(X_test_standard)\n",
    "\n",
    "print(\"R²: \", r2_score(y_test, y_pred_svm))\n",
    "print(\"Precison: \", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_svm))\n",
    "print(\"Brier Score: \", brier_score_loss(y_test, y_pred_svm))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_test, y_pred_svm, beta=0.5))\n",
    "recall_svm, precision_svm, th_svm = precision_recall_curve(y_test, y_pred_svm)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_svm, precision_svm))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar os dataset de treino e teste para treinar o modelo final\n",
    "X_train_final = pd.concat([X_train, X_test])\n",
    "y_train_final = pd.concat([y_train, y_test])\n",
    "\n",
    "# grid search para o random forest\n",
    "random_forest_final = RandomForestClassifier()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"n_estimators\": [10, 50, 100, 200, 500],\n",
    "                \"criterion\": [\"gini\", \"entropy\"]}\n",
    "grid_search = GridSearchCV(random_forest_final, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_final, y_train_final)\n",
    "\n",
    "param_grid = grid_search.best_params_ \n",
    "\n",
    "# treinar o modelo final com os melhores parâmetros\n",
    "\n",
    "random_forest_final = RandomForestClassifier(n_estimators=param_grid[\"n_estimators\"],\n",
    "                                            criterion=param_grid[\"criterion\"])\n",
    "\n",
    "random_forest_final.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  0.24233480354293757\n",
      "Precison:  0.7777777777777778\n",
      "Recall:  0.3413173652694611\n",
      "Brier Score:  0.0014604883383971307\n",
      "F-0.5 Score:  0.6193728655696988\n",
      "Area under Precision Recall Curve:  0.5582522967981631\n",
      "confusion matrix:\n",
      " [[603994    114]\n",
      " [   770    399]]\n"
     ]
    }
   ],
   "source": [
    "# salvar o modelo final\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(random_forest_final, open(\"random_forest_final.sav\", \"wb\"))\n",
    "\n",
    "# carregar o modelo final\n",
    "\n",
    "random_forest_final = pickle.load(open(\"random_forest_final.sav\", \"rb\"))\n",
    "\n",
    "# testar o modelo final\n",
    "\n",
    "y_pred_rf_final = random_forest_final.predict(X_val)\n",
    "\n",
    "print(\"R²: \", r2_score(y_val, y_pred_rf_final))\n",
    "print(\"Precison: \", precision_score(y_val, y_pred_rf_final))\n",
    "print(\"Recall: \", recall_score(y_val, y_pred_rf_final))\n",
    "print(\"Brier Score: \", brier_score_loss(y_val, y_pred_rf_final))\n",
    "print(\"F-0.5 Score: \", fbeta_score(y_val, y_pred_rf_final, beta=0.5))\n",
    "recall_rf_final, precision_rf_final, th_rf_final = precision_recall_curve(y_val, y_pred_rf_final)\n",
    "print(\"Area under Precision Recall Curve: \", auc(recall_rf_final, precision_rf_final))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_val, y_pred_rf_final))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prefeitura_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
